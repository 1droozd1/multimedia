{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1 - KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор набора данных и метрик\n",
    "\n",
    "Я выбрал датасет, содержащий данные о химическом составе различных вин. Этот датасет можно использовать как для классификации, так и для регрессии. Для классификации мы можем выделить несколько классов качества вина (например, 0 - низкое качество, 1 - среднее, 2 - высокое качество). Также этот датасет не содержит пропусков, что упрощает работу.\n",
    "\n",
    "**Классификация**: задача классификации качества вина.\n",
    "**Регрессия**: задача предсказания точного значения качества вина.\n",
    "\n",
    "**Метрики для оценки**:\n",
    " - Для классификации: Accuracy, F1-Score.\n",
    " - Для регрессии: MSE, R², MAE.\n",
    "\n",
    "**Для классификации**:\n",
    "* ```Accuracy (Точность)```: Эта метрика показывает долю правильно классифицированных примеров. Применяется, если классы сбалансированы и важна общая точность классификации.\n",
    "* ```F1-Score```: Этот показатель является средним гармоническим точности и полноты. Подходит, когда классы несбалансированы, и важно минимизировать как ложноположительные, так и ложносогласные ошибки.\n",
    "\n",
    "**Для регрессии**:\n",
    "* ```Mean Squared Error (MSE)```: Среднеквадратичная ошибка используется для измерения разницы между предсказанными и реальными значениями. Это хорошая метрика для оценки точности модели в задачах регрессии.\n",
    "* ``R² (Коэффициент детерминации)``: Это метрика, которая оценивает, какая доля вариации целевой переменной объясняется моделью. R² близкий к 1 означает хорошую модель.\n",
    "* ```Mean Absolute Error (MAE)```: Средняя абсолютная ошибка также используется для оценки отклонений между предсказанными и реальными значениями.\n",
    "\n",
    "**Практическая значимость**: Прогнозирование качества вина является реальной задачей, используемой в виноделии, чтобы оценить, какие химические компоненты оказывают влияние на качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритм KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, r2_score, mean_absolute_error, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение данных:\n",
    "* Для классификации целевая переменная y_class преобразована в бинарную (0 или 1) на основе того, если качество вина больше или равно 7, считаем его высококачественным.\n",
    "\n",
    "* Для регрессии мы оставляем точное значение качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и целевую переменную для классификации и регрессии\n",
    "X = df.drop('quality', axis=1)\n",
    "\n",
    "# Для классификации:\n",
    "y_class = (df['quality'] >= 7).astype(int)\n",
    "# Для регрессии:\n",
    "y_reg = df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение данных на обучающую и тестовую выборки (80% обучение, 20% тестирование)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_class, y_test_class = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
    "y_train_reg, y_test_reg = train_test_split(y_reg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Классификация``` с использованием KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_class = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_class.fit(X_train, y_train_class)\n",
    "y_pred_class = knn_class.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бейзлайн:\n",
      "Accuracy: 0.8562\n",
      "F1 Score: 0.3030\n"
     ]
    }
   ],
   "source": [
    "accuracy_classic_class = accuracy_score(y_test_class, y_pred_class)\n",
    "f1_classic_class = f1_score(y_test_class, y_pred_class)\n",
    "print(\"Бейзлайн:\")\n",
    "print(f\"Accuracy: {accuracy_classic_class:.4f}\")\n",
    "print(f\"F1 Score: {f1_classic_class:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор гиперпараметров с помощью GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for classification: {'metric': 'manhattan', 'n_neighbors': 11}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn_class = KNeighborsClassifier()\n",
    "grid_search_class = GridSearchCV(knn_class, param_grid, cv=5)\n",
    "grid_search_class.fit(X_train_scaled, y_train_class)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(\"Best parameters for classification:\", grid_search_class.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели с улучшениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_class = grid_search_class.best_estimator_\n",
    "\n",
    "y_pred_class = best_knn_class.predict(X_test_scaled)\n",
    "accuracy_impr_class = accuracy_score(y_test_class, y_pred_class)\n",
    "f1_impr_class = f1_score(y_test_class, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Улучшенный бейзлайн:\n",
      "Accuracy: 0.8812\n",
      "F1 Score: 0.5128\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       273\n",
      "           1       0.65      0.43      0.51        47\n",
      "\n",
      "    accuracy                           0.88       320\n",
      "   macro avg       0.78      0.69      0.72       320\n",
      "weighted avg       0.87      0.88      0.87       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Улучшенный бейзлайн:\")\n",
    "print(f\"Accuracy: {accuracy_impr_class:.4f}\")\n",
    "print(f\"F1 Score: {f1_impr_class:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем собственную версию KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Реализация Custom KNN:\n",
      "Accuracy: 0.8812\n",
      "F1 Score: 0.5128\n"
     ]
    }
   ],
   "source": [
    "class CustomKNN:\n",
    "    def __init__(self, n_neighbors=5, metric='euclidean'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "\n",
    "    def _compute_distance(self, x1, x2):\n",
    "        if self.metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "        elif self.metric == 'manhattan':\n",
    "            return np.sum(np.abs(x1 - x2))\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported metric!\")\n",
    "\n",
    "    def _get_neighbors(self, x):\n",
    "        distances = [self._compute_distance(x, x_train) for x_train in self.X_train]\n",
    "        neighbors = np.argsort(distances)[:self.n_neighbors]\n",
    "        return neighbors\n",
    "\n",
    "    def predict_classification(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            neighbors = self._get_neighbors(x)\n",
    "            neighbor_labels = self.y_train[neighbors]\n",
    "            most_common = Counter(neighbor_labels).most_common(1)[0][0]\n",
    "            predictions.append(most_common)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Обучение\n",
    "knn_custom_class = CustomKNN(n_neighbors=5)\n",
    "knn_custom_class.fit(X_train_scaled, y_train_class)\n",
    "y_pred_custom_class = knn_custom_class.predict_classification(X_test_scaled)\n",
    "\n",
    "# Метрики\n",
    "accuracy_custom_class = accuracy_score(y_test_class, y_pred_custom_class)\n",
    "f1_custom_class = f1_score(y_test_class, y_pred_custom_class)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Реализация Custom KNN:\")\n",
    "print(f\"Accuracy: {accuracy_custom_class:.4f}\")\n",
    "print(f\"F1 Score: {f1_custom_class:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним полученные резльтаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение результатов:\n",
      "Бейзлайн Accuracy: 0.8562, Улучшенный Accuracy: 0.8812, Accuracy Custom KNN : 0.8812\n",
      "Бейзлайн F1-Score: 0.3030, Улучшенный F1-Score: 0.5128, F1-Score Custom KNN: 0.5128\n"
     ]
    }
   ],
   "source": [
    "print(\"Сравнение результатов:\")\n",
    "print(f\"Бейзлайн Accuracy: {accuracy_classic_class:.4f}, Улучшенный Accuracy: {accuracy_impr_class:.4f}, Accuracy Custom KNN : {accuracy_custom_class:.4f}\")\n",
    "print(f\"Бейзлайн F1-Score: {f1_classic_class:.4f}, Улучшенный F1-Score: {f1_impr_class:.4f}, F1-Score Custom KNN: {f1_custom_class:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Регрессия``` с использованием KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_reg.fit(X_train, y_train_reg)\n",
    "y_pred_reg = knn_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Metrics:\n",
      "Mean Squared Error (MSE): 0.5320\n",
      "Mean Absolute Error (MAE): 0.5788\n",
      "R² Score: 0.1859\n"
     ]
    }
   ],
   "source": [
    "mse_сlassic = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mae_classic = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2_classic = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"Regression Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_сlassic:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_classic:.4f}\")\n",
    "print(f\"R² Score: {r2_classic:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор гиперпараметров с помощью GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for classification: {'metric': 'manhattan', 'n_neighbors': 11}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "grid_search_reg = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5)\n",
    "grid_search_reg.fit(X_train_scaled, y_train_reg)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(\"Best parameters for classification:\", grid_search_reg.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение с лучшими параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_reg = grid_search_reg.best_estimator_\n",
    "\n",
    "y_pred_reg = best_knn_reg.predict(X_test_scaled)\n",
    "mse_improved = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mae_improved = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2_improved = r2_score(y_test_reg, y_pred_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод метрик для улучшеного бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Regression Metrics:\n",
      "Mean Squared Error (MSE): 0.3689\n",
      "Mean Absolute Error (MAE): 0.4901\n",
      "R² Score: 0.4355\n"
     ]
    }
   ],
   "source": [
    "print(\"Improved Regression Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_improved:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_improved:.4f}\")\n",
    "print(f\"R² Score: {r2_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализации своей версии KNN для регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализация KNN\n",
    "class CustomKNN:\n",
    "    def __init__(self, n_neighbors=5, metric='euclidean'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "\n",
    "    def _compute_distance(self, x1, x2):\n",
    "        if self.metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "        elif self.metric == 'manhattan':\n",
    "            return np.sum(np.abs(x1 - x2))\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported metric!\")\n",
    "\n",
    "    def _get_neighbors(self, x):\n",
    "        distances = [self._compute_distance(x, x_train) for x_train in self.X_train]\n",
    "        neighbors = np.argsort(distances)[:self.n_neighbors]\n",
    "        return neighbors\n",
    "\n",
    "    def predict_regression(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            neighbors = self._get_neighbors(x)\n",
    "            neighbor_values = self.y_train[neighbors]\n",
    "            predictions.append(np.mean(neighbor_values))\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Обучение\n",
    "knn_custom_reg = CustomKNN(n_neighbors=11, metric='manhattan')\n",
    "knn_custom_reg.fit(X_train_scaled, y_train_reg)\n",
    "y_pred_custom_reg = knn_custom_reg.predict_regression(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод метрик для регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Regression Metrics:\n",
      "Mean Squared Error (MSE): 0.3689\n",
      "Mean Absolute Error (MAE): 0.4901\n",
      "R² Score: 0.4355\n"
     ]
    }
   ],
   "source": [
    "# Регрессия\n",
    "mse_custom = mean_squared_error(y_test_reg, y_pred_custom_reg)\n",
    "mae_custom = mean_absolute_error(y_test_reg, y_pred_custom_reg)\n",
    "r2_custom = r2_score(y_test_reg, y_pred_custom_reg)\n",
    "\n",
    "print(\"\\nCustom Regression Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_custom:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_custom:.4f}\")\n",
    "print(f\"R² Score: {r2_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение результатов:\n",
      "Бейзлайн MSE: 0.5320, Улучшенный MSE: 0.3689, Custom KNN MSE: 0.3689\n",
      "Бейзлайн MAE: 0.5788, Улучшенный MAE: 0.4901, Custom KNN MAE: 0.4901\n",
      "Бейзлайн R²: 0.1859, Улучшенный R²: 0.4355, Custom KNN R²: 0.4355\n"
     ]
    }
   ],
   "source": [
    "print(\"Сравнение результатов:\")\n",
    "\n",
    "print(f\"Бейзлайн MSE: {mse_сlassic:.4f}, Улучшенный MSE: {mse_improved:.4f}, Custom KNN MSE: {mse_custom:.4f}\")\n",
    "print(f\"Бейзлайн MAE: {mae_classic:.4f}, Улучшенный MAE: {mae_improved:.4f}, Custom KNN MAE: {mae_custom:.4f}\")\n",
    "print(f\"Бейзлайн R²: {r2_classic:.4f}, Улучшенный R²: {r2_improved:.4f}, Custom KNN R²: {r2_custom:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2 - Лог и Лин рег."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, mean_absolute_error, r2_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение данных:\n",
    "* Для классификации целевая переменная y_class преобразована в бинарную (0 или 1) на основе того, если качество вина больше или равно 7, считаем его высококачественным.\n",
    "\n",
    "* Для регрессии мы оставляем точное значение качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и целевую переменную для классификации и регрессии\n",
    "X = df.drop('quality', axis=1)\n",
    "\n",
    "# Для классификации:\n",
    "y_class = (df['quality'] >= 7).astype(int)\n",
    "# Для регрессии:\n",
    "y_reg = df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение данных на обучающую и тестовую выборки (80% обучение, 20% тестирование)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_class, y_test_class = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
    "y_train_reg, y_test_reg = train_test_split(y_reg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия (классификация)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем встроенный алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бейзлайн:\n",
      "Accuracy: 0.8656\n",
      "F1 Score: 0.3768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       273\n",
      "           1       0.65      0.43      0.51        47\n",
      "\n",
      "    accuracy                           0.88       320\n",
      "   macro avg       0.78      0.69      0.72       320\n",
      "weighted avg       0.87      0.88      0.87       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Логистическая регрессия для классификации\n",
    "logreg_class = LogisticRegression(max_iter=200)\n",
    "logreg_class.fit(X_train_scaled, y_train_class)\n",
    "y_pred_class_logreg = logreg_class.predict(X_test_scaled)\n",
    "\n",
    "# Оценка качества\n",
    "accuracy_logreg = accuracy_score(y_test_class, y_pred_class_logreg)\n",
    "f1_logreg = f1_score(y_test_class, y_pred_class_logreg)\n",
    "\n",
    "print(\"Бейзлайн:\")\n",
    "print(f\"Accuracy: {accuracy_logreg:.4f}\")\n",
    "print(f\"F1 Score: {f1_logreg:.4f}\")\n",
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизация гиперпараметров для улучшения базовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "param_grid_logreg = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "grid_search_logreg = GridSearchCV(LogisticRegression(max_iter=200), param_grid_logreg, cv=5)\n",
    "grid_search_logreg.fit(X_train_scaled, y_train_class)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(\"Best parameters for Logistic Regression:\", grid_search_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель с лучшими параметрами и выводим метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Улучшенный Бейзлайн:\n",
      "Accuracy: 0.8594\n",
      "F1 Score: 0.3077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       273\n",
      "           1       0.56      0.21      0.31        47\n",
      "\n",
      "    accuracy                           0.86       320\n",
      "   macro avg       0.72      0.59      0.61       320\n",
      "weighted avg       0.83      0.86      0.83       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_logreg = grid_search_logreg.best_estimator_\n",
    "\n",
    "y_pred_class = best_logreg.predict(X_test_scaled)\n",
    "\n",
    "accuracy_logreg_improved = accuracy_score(y_test_class, y_pred_class)\n",
    "f1_logreg_improved = f1_score(y_test_class, y_pred_class)\n",
    "\n",
    "print(\"Улучшенный Бейзлайн:\")\n",
    "print(f\"Accuracy: {accuracy_logreg_improved:.4f}\")\n",
    "print(f\"F1 Score: {f1_logreg_improved:.4f}\")\n",
    "\n",
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собственная реализация логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Logistic Regression Accuracy: 0.8625\n",
      "Custom Logistic Regression F1 Score: 0.3125\n"
     ]
    }
   ],
   "source": [
    "class CustomLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            model = np.dot(X, self.weights) + self.bias\n",
    "            predictions = self.sigmoid(model)\n",
    "            \n",
    "            dw = (1/n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1/n_samples) * np.sum(predictions - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        model = np.dot(X, self.weights) + self.bias\n",
    "        predictions = self.sigmoid(model)\n",
    "        return [1 if i > 0.5 else 0 for i in predictions]\n",
    "\n",
    "# Обучение кастомной логистической регрессии\n",
    "custom_logreg = CustomLogisticRegression()\n",
    "custom_logreg.fit(X_train_scaled, y_train_class)\n",
    "y_pred_class_custom_logreg = custom_logreg.predict(X_test_scaled)\n",
    "\n",
    "# Оценка качества\n",
    "accuracy_custom_logreg = accuracy_score(y_test_class, y_pred_class_custom_logreg)\n",
    "f1_custom_logreg = f1_score(y_test_class, y_pred_class_custom_logreg)\n",
    "\n",
    "print(\"Custom Logistic Regression Accuracy:\", accuracy_custom_logreg)\n",
    "print(\"Custom Logistic Regression F1 Score:\", f1_custom_logreg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение результатов:\n",
      "Бейзлайн Accuracy: 0.8656, Улучшенный Accuracy: 0.8594, Custom Accuracy: 0.8625\n",
      "Бейзлайн F1-Score: 0.3768, Улучшенный F1-Score: 0.3077, Custom F1-Score: 0.3125\n"
     ]
    }
   ],
   "source": [
    "print(\"Сравнение результатов:\")\n",
    "print(f\"Бейзлайн Accuracy: {accuracy_logreg:.4f}, Улучшенный Accuracy: {accuracy_logreg_improved:.4f}, Custom Accuracy: {accuracy_custom_logreg:.4f}\")\n",
    "print(f\"Бейзлайн F1-Score: {f1_logreg:.4f}, Улучшенный F1-Score: {f1_logreg_improved:.4f}, Custom F1-Score: {f1_custom_logreg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия (регрессия)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение встроенной реализации модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_scaled, y_train_reg)\n",
    "y_pred_reg_linreg = linreg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бейзлайн:\n",
      "Linear Regression MSE: 0.3900\n",
      "Linear Regression MAE: 0.5035\n",
      "Linear Regression R²: 0.4032\n"
     ]
    }
   ],
   "source": [
    "# Оценка качества\n",
    "mse_linreg = mean_squared_error(y_test_reg, y_pred_reg_linreg)\n",
    "mae_linreg = mean_absolute_error(y_test_reg, y_pred_reg_linreg)\n",
    "r2_linreg = r2_score(y_test_reg, y_pred_reg_linreg)\n",
    "\n",
    "print(\"Бейзлайн:\")\n",
    "print(f\"Linear Regression MSE: {mse_linreg:.4f}\")\n",
    "print(f\"Linear Regression MAE: {mae_linreg:.4f}\")\n",
    "print(f\"Linear Regression R²: {r2_linreg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применение Ridge регрессии для улучшения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Улучшенный Бейзлайн:\n",
      "Ridge Regression MSE: 0.3900\n",
      "Ridge Regression MAE: 0.5036\n",
      "Ridge Regression R²: 0.4032\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(X_train_scaled, y_train_reg)\n",
    "y_pred_reg_ridge = ridge.predict(X_test_scaled)\n",
    "\n",
    "# Оценка качества\n",
    "mse_linreg_improved = mean_squared_error(y_test_reg, y_pred_reg_ridge)\n",
    "mae_linreg_improved = mean_absolute_error(y_test_reg, y_pred_reg_ridge)\n",
    "r2_linreg_improved = r2_score(y_test_reg, y_pred_reg_ridge)\n",
    "\n",
    "print(\"Улучшенный Бейзлайн:\")\n",
    "print(f\"Ridge Regression MSE: {mse_linreg_improved:.4f}\")\n",
    "print(f\"Ridge Regression MAE: {mae_linreg_improved:.4f}\")\n",
    "print(f\"Ridge Regression R²: {r2_linreg_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация собственной версии линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Linear Regression MSE: 0.3899\n",
      "Custom Linear Regression MAE: 0.5035\n",
      "Custom Linear Regression R²: 0.4034\n"
     ]
    }
   ],
   "source": [
    "class CustomLinearRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1/n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "# Обучение кастомной линейной регрессии\n",
    "custom_linreg = CustomLinearRegression()\n",
    "custom_linreg.fit(X_train_scaled, y_train_reg)\n",
    "y_pred_reg_custom_linreg = custom_linreg.predict(X_test_scaled)\n",
    "\n",
    "# Оценка качества\n",
    "mse_custom_linreg = mean_squared_error(y_test_reg, y_pred_reg_custom_linreg)\n",
    "mae_custom_linreg = mean_absolute_error(y_test_reg, y_pred_reg_custom_linreg)\n",
    "r2_custom_linreg = r2_score(y_test_reg, y_pred_reg_custom_linreg)\n",
    "\n",
    "print(f\"Custom Linear Regression MSE: {mse_custom_linreg:.4f}\")\n",
    "print(f\"Custom Linear Regression MAE: {mae_custom_linreg:.4f}\")\n",
    "print(f\"Custom Linear Regression R²: {r2_custom_linreg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение результатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение результатов:\n",
      "Бейзлайн MSE: 0.3900, Улучшенный MSE: 0.3900, Custom MSE: 0.3899\n",
      "Бейзлайн MAE: 0.5035, Улучшенный MAE: 0.5036, Custom MAE: 0.5035\n",
      "Бейзлайн R²: 0.4032, Улучшенный R²: 0.4032, Custom R²: 0.4034\n"
     ]
    }
   ],
   "source": [
    "print(\"Сравнение результатов:\")\n",
    "print(f\"Бейзлайн MSE: {mse_linreg:.4f}, Улучшенный MSE: {mse_linreg_improved:.4f}, Custom MSE: {mse_custom_linreg:.4f}\")\n",
    "print(f\"Бейзлайн MAE: {mae_linreg:.4f}, Улучшенный MAE: {mae_linreg_improved:.4f}, Custom MAE: {mae_custom_linreg:.4f}\")\n",
    "print(f\"Бейзлайн R²: {r2_linreg:.4f}, Улучшенный R²: {r2_linreg_improved:.4f}, Custom R²: {r2_custom_linreg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №3 - Решающее дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение данных:\n",
    "* Для классификации целевая переменная y_class преобразована в бинарную (0 или 1) на основе того, если качество вина больше или равно 7, считаем его высококачественным.\n",
    "\n",
    "* Для регрессии мы оставляем точное значение качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и целевую переменную для классификации и регрессии\n",
    "X = df.drop('quality', axis=1)\n",
    "\n",
    "# Для классификации:\n",
    "y_class = (df['quality'] >= 7).astype(int)\n",
    "# Для регрессии:\n",
    "y_reg = df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение данных на обучающую и тестовую выборки (80% обучение, 20% тестирование)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_class, y_test_class = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
    "y_train_reg, y_test_reg = train_test_split(y_reg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем встроенную версию решающего дерева для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бейзлайн: Решающее дерево без настройки гиперпараметров\n",
    "dt_clf_baseline = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf_baseline.fit(X_train_scaled, y_train_class)\n",
    "\n",
    "# Предсказания и метрики\n",
    "y_pred_baseline_class = dt_clf_baseline.predict(X_test_scaled)\n",
    "accuracy_tree_class = accuracy_score(y_test_class, y_pred_baseline_class)\n",
    "f1_tree_class = f1_score(y_test_class, y_pred_baseline_class, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бейзлайн:\n",
      "Accuracy: 0.8719\n",
      "F1-Score: 0.8689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93       273\n",
      "           1       0.57      0.51      0.54        47\n",
      "\n",
      "    accuracy                           0.87       320\n",
      "   macro avg       0.74      0.72      0.73       320\n",
      "weighted avg       0.87      0.87      0.87       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Бейзлайн:\")\n",
    "print(f\"Accuracy: {accuracy_tree_class:.4f}\")\n",
    "print(f\"F1-Score: {f1_tree_class:.4f}\")\n",
    "\n",
    "print(classification_report(y_test_class, y_pred_baseline_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем улучшеный бейзлайн с помощи настройки гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для настройки гиперпараметров\n",
    "param_grid_class = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Решающее дерево с GridSearch\n",
    "grid_search_clf = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_class, cv=5)\n",
    "grid_search_clf.fit(X_train_scaled, y_train_class)\n",
    "\n",
    "# Лучшие параметры и метрики\n",
    "best_params_class = grid_search_clf.best_params_\n",
    "y_pred_improved_class = grid_search_clf.best_estimator_.predict(X_test_scaled)\n",
    "accuracy_tree_improved = accuracy_score(y_test_class, y_pred_improved_class)\n",
    "f1_tree_improved = f1_score(y_test_class, y_pred_improved_class, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Улучшенный Бейзлайн:\n",
      "Accuracy: 0.8594\n",
      "F1-Score: 0.8344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       273\n",
      "           1       0.55      0.23      0.33        47\n",
      "\n",
      "    accuracy                           0.86       320\n",
      "   macro avg       0.72      0.60      0.62       320\n",
      "weighted avg       0.83      0.86      0.83       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Улучшенный Бейзлайн:\")\n",
    "print(f\"Accuracy: {accuracy_tree_improved:.4f}\")\n",
    "print(f\"F1-Score: {f1_tree_improved:.4f}\")\n",
    "print(classification_report(y_test_class, y_pred_improved_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем собственнуб версию решающего дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, task='classification'):\n",
    "        \"\"\"\n",
    "        Универсальное дерево решений.\n",
    "\n",
    "        Параметры:\n",
    "        - max_depth: Максимальная глубина дерева.\n",
    "        - min_samples_split: Минимальное число элементов для разделения.\n",
    "        - task: Тип задачи ('classification' или 'regression').\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.task = task\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение дерева решений.\"\"\"\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание для входных данных.\"\"\"\n",
    "        return np.array([self._predict_single(dict(zip(X.columns, x)), self.tree) for x in X.values])\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        \"\"\"Вычисление энтропии.\"\"\"\n",
    "        counts = np.bincount(y)\n",
    "        probabilities = counts / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
    "\n",
    "    def _gini(self, y):\n",
    "        \"\"\"Вычисление индекса Джини.\"\"\"\n",
    "        counts = np.bincount(y)\n",
    "        probabilities = counts / len(y)\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "    def _mse(self, y):\n",
    "        \"\"\"Вычисление MSE.\"\"\"\n",
    "        mean = np.mean(y)\n",
    "        return np.mean((y - mean) ** 2)\n",
    "\n",
    "    def _criterion(self, y, y_left, y_right):\n",
    "        \"\"\"Вычисление критерия разбиения.\"\"\"\n",
    "        if self.task == 'classification':\n",
    "            return self._entropy(y) - (\n",
    "                len(y_left) / len(y) * self._entropy(y_left) + len(y_right) / len(y) * self._entropy(y_right)\n",
    "            )\n",
    "        elif self.task == 'regression':\n",
    "            return self._mse(y) - (\n",
    "                len(y_left) / len(y) * self._mse(y_left) + len(y_right) / len(y) * self._mse(y_right)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Неподдерживаемая задача. Используйте 'classification' или 'regression'.\")\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"Поиск наилучшего разбиения данных.\"\"\"\n",
    "        best_gain = -1\n",
    "        best_split = None\n",
    "        best_column = None\n",
    "\n",
    "        for column in X.columns:\n",
    "            values = X[column].unique()\n",
    "            for value in values:\n",
    "                y_left = y[X[column] <= value]\n",
    "                y_right = y[X[column] > value]\n",
    "\n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "\n",
    "                gain = self._criterion(y, y_left, y_right)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split = value\n",
    "                    best_column = column\n",
    "\n",
    "        return best_column, best_split, best_gain\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        \"\"\"Рекурсивное построение дерева.\"\"\"\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or len(y) < self.min_samples_split or len(set(y)) == 1:\n",
    "            if self.task == 'classification':\n",
    "                return {'leaf': True, 'prediction': Counter(y).most_common(1)[0][0]}\n",
    "            elif self.task == 'regression':\n",
    "                return {'leaf': True, 'prediction': np.mean(y)}\n",
    "\n",
    "        column, split_value, gain = self._best_split(X, y)\n",
    "\n",
    "        if gain == -1:\n",
    "            if self.task == 'classification':\n",
    "                return {'leaf': True, 'prediction': Counter(y).most_common(1)[0][0]}\n",
    "            elif self.task == 'regression':\n",
    "                return {'leaf': True, 'prediction': np.mean(y)}\n",
    "\n",
    "        left_indices = X[column] <= split_value\n",
    "        right_indices = X[column] > split_value\n",
    "\n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return {\n",
    "            'leaf': False,\n",
    "            'column': column,\n",
    "            'split_value': split_value,\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "\n",
    "    def _predict_single(self, x, tree):\n",
    "        \"\"\"Предсказание для одного примера.\"\"\"\n",
    "        if tree['leaf']:\n",
    "            return tree['prediction']\n",
    "\n",
    "        if x[tree['column']] <= tree['split_value']:\n",
    "            return self._predict_single(x, tree['left'])\n",
    "        else:\n",
    "            return self._predict_single(x, tree['right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель и выведем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кастомный Бейзлайн:\n",
      "Accuracy: 0.8969\n",
      "F1-Score: 0.5926\n"
     ]
    }
   ],
   "source": [
    "tree_classifier = CustomDecisionTree(max_depth=5, min_samples_split=10, task='classification')\n",
    "tree_classifier.fit(X_train, y_train_class)\n",
    "\n",
    "y_pred_custom_class = tree_classifier.predict(X_test)\n",
    "\n",
    "accuracy_tree_custom = accuracy_score(y_test_class, y_pred_custom_class)\n",
    "f1_tree_custom = f1_score(y_test_class, y_pred_custom_class)\n",
    "\n",
    "print(\"Кастомный Бейзлайн:\")\n",
    "print(f\"Accuracy: {accuracy_tree_custom:.4f}\")\n",
    "print(f\"F1-Score: {f1_tree_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод и сравнение всех полученных метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сравнение результатов (Классификация):\n",
      "Бейзлайн Accuracy: 0.8719, Улучшенная Accuracy: 0.8594, Custom Accuracy: 0.8969\n",
      "Бейзлайн F1-Score: 0.8689, Улучшенная F1-Score: 0.8344, Custom F1-Score: 0.5926\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСравнение результатов (Классификация):\")\n",
    "print(f\"Бейзлайн Accuracy: {accuracy_tree_class:.4f}, Улучшенная Accuracy: {accuracy_tree_improved:.4f}, Custom Accuracy: {accuracy_tree_custom:.4f}\")\n",
    "print(f\"Бейзлайн F1-Score: {f1_tree_class:.4f}, Улучшенная F1-Score: {f1_tree_improved:.4f}, Custom F1-Score: {f1_tree_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем встроенную версию для обучения модели и выведем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бейзлайн:\n",
      "MSE: 0.6125\n",
      "MAE: 0.4625\n",
      "R²: 0.0627\n"
     ]
    }
   ],
   "source": [
    "# Бейзлайн\n",
    "dt_reg_baseline = DecisionTreeRegressor(random_state=42)\n",
    "dt_reg_baseline.fit(X_train_scaled, y_train_reg)\n",
    "\n",
    "# Предсказания и метрики\n",
    "y_pred_baseline_reg = dt_reg_baseline.predict(X_test_scaled)\n",
    "mse_tree = mean_squared_error(y_test_reg, y_pred_baseline_reg)\n",
    "mae_tree = mean_absolute_error(y_test_reg, y_pred_baseline_reg)\n",
    "r2_tree = r2_score(y_test_reg, y_pred_baseline_reg)\n",
    "\n",
    "print(\"Бейзлайн:\")\n",
    "print(f\"MSE: {mse_tree:.4f}\")\n",
    "print(f\"MAE: {mae_tree:.4f}\")\n",
    "print(f\"R²: {r2_tree:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроим гиперпараметры и выведем полученные метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Улучшенный Бейзлайн:\n",
      "MSE: 0.4400\n",
      "MAE: 0.5062\n",
      "R²: 0.3267\n"
     ]
    }
   ],
   "source": [
    "# Параметры для настройки гиперпараметров\n",
    "param_grid_reg = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Решающее дерево с GridSearch\n",
    "grid_search_reg = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid_reg, cv=5)\n",
    "grid_search_reg.fit(X_train_scaled, y_train_reg)\n",
    "\n",
    "# Лучшие параметры и метрики\n",
    "best_params_reg = grid_search_reg.best_params_\n",
    "y_pred_improved_reg = grid_search_reg.best_estimator_.predict(X_test_scaled)\n",
    "mse_tree_improved = mean_squared_error(y_test_reg, y_pred_improved_reg)\n",
    "mae_tree_improved = mean_absolute_error(y_test_reg, y_pred_improved_reg)\n",
    "r2_tree_improved = r2_score(y_test_reg, y_pred_improved_reg)\n",
    "\n",
    "print(\"Улучшенный Бейзлайн:\")\n",
    "print(f\"MSE: {mse_tree_improved:.4f}\")\n",
    "print(f\"MAE: {mae_tree_improved:.4f}\")\n",
    "print(f\"R²: {r2_tree_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем собственную версию решающего дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, task='classification'):\n",
    "        \"\"\"\n",
    "        Универсальное дерево решений.\n",
    "\n",
    "        Параметры:\n",
    "        - max_depth: Максимальная глубина дерева.\n",
    "        - min_samples_split: Минимальное число элементов для разделения.\n",
    "        - task: Тип задачи ('classification' или 'regression').\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.task = task\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение дерева решений.\"\"\"\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание для входных данных.\"\"\"\n",
    "        return np.array([self._predict_single(dict(zip(X.columns, x)), self.tree) for x in X.values])\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        \"\"\"Вычисление энтропии.\"\"\"\n",
    "        counts = np.bincount(y)\n",
    "        probabilities = counts / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
    "\n",
    "    def _gini(self, y):\n",
    "        \"\"\"Вычисление индекса Джини.\"\"\"\n",
    "        counts = np.bincount(y)\n",
    "        probabilities = counts / len(y)\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "    def _mse(self, y):\n",
    "        \"\"\"Вычисление MSE.\"\"\"\n",
    "        mean = np.mean(y)\n",
    "        return np.mean((y - mean) ** 2)\n",
    "\n",
    "    def _criterion(self, y, y_left, y_right):\n",
    "        \"\"\"Вычисление критерия разбиения.\"\"\"\n",
    "        if self.task == 'classification':\n",
    "            return self._entropy(y) - (\n",
    "                len(y_left) / len(y) * self._entropy(y_left) + len(y_right) / len(y) * self._entropy(y_right)\n",
    "            )\n",
    "        elif self.task == 'regression':\n",
    "            return self._mse(y) - (\n",
    "                len(y_left) / len(y) * self._mse(y_left) + len(y_right) / len(y) * self._mse(y_right)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Неподдерживаемая задача. Используйте 'classification' или 'regression'.\")\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"Поиск наилучшего разбиения данных.\"\"\"\n",
    "        best_gain = -1\n",
    "        best_split = None\n",
    "        best_column = None\n",
    "\n",
    "        for column in X.columns:\n",
    "            values = X[column].unique()\n",
    "            for value in values:\n",
    "                y_left = y[X[column] <= value]\n",
    "                y_right = y[X[column] > value]\n",
    "\n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "\n",
    "                gain = self._criterion(y, y_left, y_right)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split = value\n",
    "                    best_column = column\n",
    "\n",
    "        return best_column, best_split, best_gain\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        \"\"\"Рекурсивное построение дерева.\"\"\"\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or len(y) < self.min_samples_split or len(set(y)) == 1:\n",
    "            if self.task == 'classification':\n",
    "                return {'leaf': True, 'prediction': Counter(y).most_common(1)[0][0]}\n",
    "            elif self.task == 'regression':\n",
    "                return {'leaf': True, 'prediction': np.mean(y)}\n",
    "\n",
    "        column, split_value, gain = self._best_split(X, y)\n",
    "\n",
    "        if gain == -1:\n",
    "            if self.task == 'classification':\n",
    "                return {'leaf': True, 'prediction': Counter(y).most_common(1)[0][0]}\n",
    "            elif self.task == 'regression':\n",
    "                return {'leaf': True, 'prediction': np.mean(y)}\n",
    "\n",
    "        left_indices = X[column] <= split_value\n",
    "        right_indices = X[column] > split_value\n",
    "\n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return {\n",
    "            'leaf': False,\n",
    "            'column': column,\n",
    "            'split_value': split_value,\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "\n",
    "    def _predict_single(self, x, tree):\n",
    "        \"\"\"Предсказание для одного примера.\"\"\"\n",
    "        if tree['leaf']:\n",
    "            return tree['prediction']\n",
    "\n",
    "        if x[tree['column']] <= tree['split_value']:\n",
    "            return self._predict_single(x, tree['left'])\n",
    "        else:\n",
    "            return self._predict_single(x, tree['right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель и выведем полученные метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кастомный Бейзлайн:\n",
      "MSE: 0.4062\n",
      "MAE: 0.4890\n",
      "R²: 0.3784\n"
     ]
    }
   ],
   "source": [
    "tree_regressor = CustomDecisionTree(max_depth=5, min_samples_split=10, task='regression')\n",
    "tree_regressor.fit(X_train, y_train_reg)\n",
    "\n",
    "y_pred_custom_reg = tree_regressor.predict(X_test)\n",
    "\n",
    "mse_tree_custom = mean_squared_error(y_test_reg, y_pred_custom_reg)\n",
    "mae_tree_custom = mean_absolute_error(y_test_reg, y_pred_custom_reg)\n",
    "r2_tree_custom = r2_score(y_test_reg, y_pred_custom_reg)\n",
    "\n",
    "print(\"Кастомный Бейзлайн:\")\n",
    "print(f\"MSE: {mse_tree_custom:.4f}\")\n",
    "print(f\"MAE: {mae_tree_custom:.4f}\")\n",
    "print(f\"R²: {r2_tree_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод и сравнение всех метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сравнение результатов (Регрессия):\n",
      "Бейзлайн MSE: 0.6125, Улучшенная MSE: 0.4400, Custom MSE: 0.4062\n",
      "Бейзлайн MAE: 0.4625, Улучшенная MAE: 0.5062, Custom MAE: 0.4890\n",
      "Бейзлайн R²: 0.0627, Улучшенная R²: 0.3267, Custom R²: 0.3784\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСравнение результатов (Регрессия):\")\n",
    "print(f\"Бейзлайн MSE: {mse_tree:.4f}, Улучшенная MSE: {mse_tree_improved:.4f}, Custom MSE: {mse_tree_custom:.4f}\")\n",
    "print(f\"Бейзлайн MAE: {mae_tree:.4f}, Улучшенная MAE: {mae_tree_improved:.4f}, Custom MAE: {mae_tree_custom:.4f}\")\n",
    "print(f\"Бейзлайн R²: {r2_tree:.4f}, Улучшенная R²: {r2_tree_improved:.4f}, Custom R²: {r2_tree_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4 - Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение данных:\n",
    "* Для классификации целевая переменная y_class преобразована в бинарную (0 или 1) на основе того, если качество вина больше или равно 7, считаем его высококачественным.\n",
    "\n",
    "* Для регрессии мы оставляем точное значение качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и целевую переменную для классификации и регрессии\n",
    "X = df.drop('quality', axis=1)\n",
    "\n",
    "# Для классификации:\n",
    "y_class = (df['quality'] >= 7).astype(int)\n",
    "# Для регрессии:\n",
    "y_reg = df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение данных на обучающую и тестовую выборки (80% обучение, 20% тестирование)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_class, y_test_class = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
    "y_train_reg, y_test_reg = train_test_split(y_reg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем встроенную версию случайного леса для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Встроенный случайный лес:\n",
      "Accuracy: 0.9000\n",
      "F1-Score: 0.6000\n"
     ]
    }
   ],
   "source": [
    "# Встроенный случайный лес для классификации\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train_class)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_class = rf_classifier.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "accuracy_random_tree = accuracy_score(y_test_class, y_pred_class)\n",
    "f1_random_tree = f1_score(y_test_class, y_pred_class)\n",
    "\n",
    "print(\"Встроенный случайный лес:\")\n",
    "print(f\"Accuracy: {accuracy_random_tree:.4f}\")\n",
    "print(f\"F1-Score: {f1_random_tree:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем улучшеный бейзлайн с помощи настройки гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for RandomForest Classifier: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Улучшенный случайный лес:\n",
      "Accuracy: 0.9031\n",
      "F1-Score: 0.6076\n"
     ]
    }
   ],
   "source": [
    "# Параметры для GridSearch\n",
    "param_grid_classifier = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_classifier = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_classifier, cv=5)\n",
    "grid_search_classifier.fit(X_train, y_train_class)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(\"Best parameters for RandomForest Classifier:\", grid_search_classifier.best_params_)\n",
    "\n",
    "# Обучение модели с лучшими параметрами\n",
    "best_rf_classifier = grid_search_classifier.best_estimator_\n",
    "y_pred_class_best = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "accuracy_random_tree_improved = accuracy_score(y_test_class, y_pred_class_best)\n",
    "f1_random_tree_improved = f1_score(y_test_class, y_pred_class_best)\n",
    "\n",
    "print(\"Улучшенный случайный лес:\")\n",
    "print(f\"Accuracy: {accuracy_random_tree_improved:.4f}\")\n",
    "print(f\"F1-Score: {f1_random_tree_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем собственную версию случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRandomForest(BaseEstimator):\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, task='classification'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.task = task\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение случайного леса.\"\"\"\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Бутстраппинг: случайная выборка данных с возвращением\n",
    "            X_bootstrap, y_bootstrap = self._bootstrap(X, y)\n",
    "            tree = self._create_tree(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание для входных данных.\"\"\"\n",
    "        if self.task == 'classification':\n",
    "            # Классификация: голосование деревьев\n",
    "            predictions = [tree.predict(X) for tree in self.trees]\n",
    "            return np.array([self._majority_vote(pred) for pred in zip(*predictions)])\n",
    "        else:\n",
    "            # Регрессия: усреднение предсказаний\n",
    "            predictions = [tree.predict(X) for tree in self.trees]\n",
    "            return np.mean(predictions, axis=0)\n",
    "\n",
    "    def _bootstrap(self, X, y):\n",
    "        \"\"\"Метод бутстраппинга: случайная выборка данных с возвращением.\"\"\"\n",
    "        n_samples = len(X)\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X.iloc[indices], y.iloc[indices]\n",
    "\n",
    "    def _create_tree(self, X, y):\n",
    "        \"\"\"Создание решающего дерева.\"\"\"\n",
    "        if self.task == 'classification':\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "        else:\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "        tree.fit(X, y)\n",
    "        return tree\n",
    "\n",
    "    def _majority_vote(self, predictions):\n",
    "        \"\"\"Голосование деревьев (для классификации).\"\"\"\n",
    "        values, counts = np.unique(predictions, return_counts=True)\n",
    "        return values[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели и вывод метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собственная реализация случайного леса:\n",
      "Accuracy: 0.8562\n",
      "F1-Score: 0.3429\n"
     ]
    }
   ],
   "source": [
    "# Собственная реализация случайного леса для классификации\n",
    "custom_rf_classifier = CustomRandomForest(n_estimators=100, max_depth=5, min_samples_split=10, task='classification')\n",
    "custom_rf_classifier.fit(X_train, y_train_class)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_custom_class = custom_rf_classifier.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "accuracy_random_tree_custom = accuracy_score(y_test_class, y_pred_custom_class)\n",
    "f1_random_tree_custom = f1_score(y_test_class, y_pred_custom_class)\n",
    "\n",
    "print(\"Собственная реализация случайного леса:\")\n",
    "print(f\"Accuracy: {accuracy_random_tree_custom:.4f}\")\n",
    "print(f\"F1-Score: {f1_random_tree_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод и сравнение всех полученных ранее метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сравнение результатов:\n",
      "Бейзлайн Accuracy: 0.9000, Улучшенная Accuracy: 0.9031, Custom Accuracy: 0.8562\n",
      "Бейзлайн F1-Score: 0.6000, Улучшенная F1-Score: 0.6076, Custom F1-Score: 0.3429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСравнение результатов:\")\n",
    "print(f\"Бейзлайн Accuracy: {accuracy_random_tree:.4f}, Улучшенная Accuracy: {accuracy_random_tree_improved:.4f}, Custom Accuracy: {accuracy_random_tree_custom:.4f}\")\n",
    "print(f\"Бейзлайн F1-Score: {f1_random_tree:.4f}, Улучшенная F1-Score: {f1_random_tree_improved:.4f}, Custom F1-Score: {f1_random_tree_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем встроенную версию случайного леса для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Встроенный случайный лес:\n",
      "MSE: 0.3012\n",
      "MAE: 0.4224\n",
      "R²: 0.5390\n"
     ]
    }
   ],
   "source": [
    "# Встроенный случайный лес для регрессии\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "rf_regressor.fit(X_train, y_train_reg)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_reg = rf_regressor.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "mse_random_tree = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mae_random_tree = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2_random_tree = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"Встроенный случайный лес:\")\n",
    "print(f\"MSE: {mse_random_tree:.4f}\")\n",
    "print(f\"MAE: {mae_random_tree:.4f}\")\n",
    "print(f\"R²: {r2_random_tree:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем улучшеный бейзлайн с помощи настройки гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for RandomForest Regressor: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Улучшенный случайный лес:\n",
      "MSE: 0.3059\n",
      "MAE: 0.4251\n",
      "R²: 0.5319\n"
     ]
    }
   ],
   "source": [
    "# Параметры для GridSearch\n",
    "param_grid_regressor = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_regressor = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_regressor, cv=5)\n",
    "grid_search_regressor.fit(X_train, y_train_reg)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(\"Best parameters for RandomForest Regressor:\", grid_search_regressor.best_params_)\n",
    "\n",
    "# Обучение модели с лучшими параметрами\n",
    "best_rf_regressor = grid_search_regressor.best_estimator_\n",
    "y_pred_reg_best = best_rf_regressor.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "mse_random_tree_improved = mean_squared_error(y_test_reg, y_pred_reg_best)\n",
    "mae_random_tree_improved = mean_absolute_error(y_test_reg, y_pred_reg_best)\n",
    "r2_random_tree_improved = r2_score(y_test_reg, y_pred_reg_best)\n",
    "\n",
    "print(\"Улучшенный случайный лес:\")\n",
    "print(f\"MSE: {mse_random_tree_improved:.4f}\")\n",
    "print(f\"MAE: {mae_random_tree_improved:.4f}\")\n",
    "print(f\"R²: {r2_random_tree_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем собственную версию случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRandomForest(BaseEstimator):\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, task='classification'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.task = task\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение случайного леса.\"\"\"\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Бутстраппинг: случайная выборка данных с возвращением\n",
    "            X_bootstrap, y_bootstrap = self._bootstrap(X, y)\n",
    "            tree = self._create_tree(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание для входных данных.\"\"\"\n",
    "        if self.task == 'classification':\n",
    "            # Классификация: голосование деревьев\n",
    "            predictions = [tree.predict(X) for tree in self.trees]\n",
    "            return np.array([self._majority_vote(pred) for pred in zip(*predictions)])\n",
    "        else:\n",
    "            # Регрессия: усреднение предсказаний\n",
    "            predictions = [tree.predict(X) for tree in self.trees]\n",
    "            return np.mean(predictions, axis=0)\n",
    "\n",
    "    def _bootstrap(self, X, y):\n",
    "        \"\"\"Метод бутстраппинга: случайная выборка данных с возвращением.\"\"\"\n",
    "        n_samples = len(X)\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X.iloc[indices], y.iloc[indices]\n",
    "\n",
    "    def _create_tree(self, X, y):\n",
    "        \"\"\"Создание решающего дерева.\"\"\"\n",
    "        if self.task == 'classification':\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "        else:\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "        tree.fit(X, y)\n",
    "        return tree\n",
    "\n",
    "    def _majority_vote(self, predictions):\n",
    "        \"\"\"Голосование деревьев (для классификации).\"\"\"\n",
    "        values, counts = np.unique(predictions, return_counts=True)\n",
    "        return values[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели и вывод метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собственная реализация случайного леса:\n",
      "MSE: 0.3731\n",
      "MAE: 0.4916\n",
      "R²: 0.4291\n"
     ]
    }
   ],
   "source": [
    "# Собственная реализация случайного леса для регрессии\n",
    "custom_rf_regressor = CustomRandomForest(n_estimators=100, max_depth=5, min_samples_split=10, task='regression')\n",
    "custom_rf_regressor.fit(X_train, y_train_reg)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_custom_reg = custom_rf_regressor.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "mse_random_tree_custom = mean_squared_error(y_test_reg, y_pred_custom_reg)\n",
    "mae_random_tree_custom = mean_absolute_error(y_test_reg, y_pred_custom_reg)\n",
    "r2_random_tree_custom = r2_score(y_test_reg, y_pred_custom_reg)\n",
    "\n",
    "print(\"Собственная реализация случайного леса:\")\n",
    "print(f\"MSE: {mse_random_tree_custom:.4f}\")\n",
    "print(f\"MAE: {mae_random_tree_custom:.4f}\")\n",
    "print(f\"R²: {r2_random_tree_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод и сравнение всех полученных ранее метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение результатов:\n",
      "Бейзлайн MSE: 0.3012, Улучшенная MSE: 0.3059, Custom MSE: 0.3731\n",
      "Бейзлайн MAE: 0.4224, Улучшенная MAE: 0.4251, Custom MAE: 0.4916\n",
      "Бейзлайн R²: 0.5390, Улучшенная R²: 0.5319, Custom R²: 0.4291\n"
     ]
    }
   ],
   "source": [
    "print(\"Сравнение результатов:\")\n",
    "print(f\"Бейзлайн MSE: {mse_random_tree:.4f}, Улучшенная MSE: {mse_random_tree_improved:.4f}, Custom MSE: {mse_random_tree_custom:.4f}\")\n",
    "print(f\"Бейзлайн MAE: {mae_random_tree:.4f}, Улучшенная MAE: {mae_random_tree_improved:.4f}, Custom MAE: {mae_random_tree_custom:.4f}\")\n",
    "print(f\"Бейзлайн R²: {r2_random_tree:.4f}, Улучшенная R²: {r2_random_tree_improved:.4f}, Custom R²: {r2_random_tree_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №5 - Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение данных:\n",
    "* Для классификации целевая переменная y_class преобразована в бинарную (0 или 1) на основе того, если качество вина больше или равно 7, считаем его высококачественным.\n",
    "\n",
    "* Для регрессии мы оставляем точное значение качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и целевую переменную для классификации и регрессии\n",
    "X = df.drop('quality', axis=1)\n",
    "\n",
    "# Для классификации:\n",
    "y_class = (df['quality'] >= 7).astype(int)\n",
    "# Для регрессии:\n",
    "y_reg = df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение данных на обучающую и тестовую выборки (80% обучение, 20% тестирование)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на обучающие и тестовые данные\n",
    "X_train, X_test, y_train_class, y_test_class = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем встроенную версию для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Встроенный градиентный бустинг:\n",
      "Accuracy: 0.8812\n",
      "F1-Score: 0.5250\n"
     ]
    }
   ],
   "source": [
    "# Встроенный градиентный бустинг для классификации\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train_class)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_class = gb_classifier.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "accuracy_gradient = accuracy_score(y_test_class, y_pred_class)\n",
    "f1_gradient = f1_score(y_test_class, y_pred_class)\n",
    "\n",
    "print(\"Встроенный градиентный бустинг:\")\n",
    "print(f\"Accuracy: {accuracy_gradient:.4f}\")\n",
    "print(f\"F1-Score: {f1_gradient:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем улучшеный бейзлайн с помощи настройки гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for GradientBoosting Classifier: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Улучшенный градиентный бустинг:\n",
      "Accuracy: 0.8938\n",
      "F1-Score: 0.8938\n"
     ]
    }
   ],
   "source": [
    "# Параметры для GridSearch\n",
    "param_grid_classifier = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_classifier = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid_classifier, cv=5)\n",
    "grid_search_classifier.fit(X_train, y_train_class)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(\"Best parameters for GradientBoosting Classifier:\", grid_search_classifier.best_params_)\n",
    "\n",
    "# Обучение модели с лучшими параметрами\n",
    "best_gb_classifier = grid_search_classifier.best_estimator_\n",
    "y_pred_class_best = best_gb_classifier.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "accuracy_gradient_improved = accuracy_score(y_test_class, y_pred_class_best)\n",
    "f1_gradient_improved = f1_score(y_test_class, y_pred_class_best)\n",
    "\n",
    "print(\"Улучшенный градиентный бустинг:\")\n",
    "print(f\"Accuracy: {accuracy_gradient_improved:.4f}\")\n",
    "print(f\"F1-Score: {accuracy_gradient_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем собственную версию градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGradientBoosting(BaseEstimator):\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, task='classification'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.task = task\n",
    "        self.trees = []\n",
    "        self.init_value = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение градиентного бустинга.\"\"\"\n",
    "        # Определяем начальное значение\n",
    "        if self.task == 'classification':\n",
    "            self.init_value = np.log(np.mean(y) / (1 - np.mean(y)))  # Для классификации\n",
    "        else:\n",
    "            self.init_value = np.mean(y)  # Для регрессии\n",
    "\n",
    "        # Инициализация предсказаний\n",
    "        y_pred = np.full(y.shape, self.init_value, dtype=np.float64)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Вычисление ошибок\n",
    "            if self.task == 'classification':\n",
    "                residuals = y - (1 / (1 + np.exp(-y_pred)))  # Используем логистическую функцию для классификации\n",
    "            else:\n",
    "                residuals = y - y_pred  # Для регрессии\n",
    "\n",
    "            # Выбор типа дерева\n",
    "            if self.task == 'classification':\n",
    "                tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            else:\n",
    "                tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "\n",
    "            # Обучение дерева на остатках\n",
    "            tree.fit(X, residuals)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            # Обновление предсказаний\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание значений.\"\"\"\n",
    "        y_pred = np.full(X.shape[0], self.init_value, dtype=np.float64)\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "\n",
    "        if self.task == 'classification':\n",
    "            return (y_pred > 0).astype(int)  # Бинарная классификация\n",
    "        return y_pred  # Для регрессии\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Предсказание вероятностей для классификации.\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return 1 / (1 + np.exp(-y_pred))  # Логистическая функция\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели и вывод полученных метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собственная реализация градиентного бустинга:\n",
      "Accuracy: 0.8750\n",
      "F1-Score: 0.8750\n"
     ]
    }
   ],
   "source": [
    "# Собственная реализация градиентного бустинга для классификации\n",
    "custom_gb_classifier = CustomGradientBoosting(n_estimators=100, learning_rate=0.1, max_depth=3, task='classification')\n",
    "custom_gb_classifier.fit(X_train, y_train_class)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_custom_class = custom_gb_classifier.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "accuracy_gradient_custom = accuracy_score(y_test_class, y_pred_custom_class)\n",
    "f1_gradient_custom = f1_score(y_test_class, y_pred_custom_class)\n",
    "\n",
    "print(\"Собственная реализация градиентного бустинга:\")\n",
    "print(f\"Accuracy: {accuracy_gradient_custom:.4f}\")\n",
    "print(f\"F1-Score: {accuracy_gradient_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод и сравнение полученных метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сравнение результатов:\n",
      "Бейзлайн Accuracy: 0.8812, Улучшенная Accuracy: 0.8938, Custom Accuracy: 0.8750\n",
      "Бейзлайн F1-Score: 0.5250, Улучшенная F1-Score: 0.6047, Custom F1-Score: 0.3548\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСравнение результатов:\")\n",
    "print(f\"Бейзлайн Accuracy: {accuracy_gradient:.4f}, Улучшенная Accuracy: {accuracy_gradient_improved:.4f}, Custom Accuracy: {accuracy_gradient_custom:.4f}\")\n",
    "print(f\"Бейзлайн F1-Score: {f1_gradient:.4f}, Улучшенная F1-Score: {f1_gradient_improved:.4f}, Custom F1-Score: {f1_gradient_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем встроенную версию для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Встроенный градиентный бустинг:\n",
      "MSE: 0.3623\n",
      "MAE: 0.4849\n",
      "R²: 0.4456\n"
     ]
    }
   ],
   "source": [
    "# Встроенный градиентный бустинг для регрессии\n",
    "gb_regressor = GradientBoostingRegressor(random_state=42)\n",
    "gb_regressor.fit(X_train, y_train_reg)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_reg = gb_regressor.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "mse_gradient = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mae_gradient = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2_gradient = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"Встроенный градиентный бустинг:\")\n",
    "print(f\"MSE: {mse_gradient:.4f}\")\n",
    "print(f\"MAE: {mae_gradient:.4f}\")\n",
    "print(f\"R²: {r2_gradient:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем улучшеный бейзлайн с помощи настройки гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for GradientBoosting Regressor: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Улучшенный градиентный бустинг:\n",
      "MSE: 0.3454\n",
      "MAE: 0.4554\n",
      "R²: 0.4715\n"
     ]
    }
   ],
   "source": [
    "# Параметры для GridSearch\n",
    "param_grid_regressor = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "grid_search_regressor = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid_regressor, cv=5)\n",
    "grid_search_regressor.fit(X_train, y_train_reg)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(\"Best parameters for GradientBoosting Regressor:\", grid_search_regressor.best_params_)\n",
    "\n",
    "# Обучение модели с лучшими параметрами\n",
    "best_gb_regressor = grid_search_regressor.best_estimator_\n",
    "y_pred_reg_best = best_gb_regressor.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "mse_gradient_improved = mean_squared_error(y_test_reg, y_pred_reg_best)\n",
    "mae_gradient_improved = mean_absolute_error(y_test_reg, y_pred_reg_best)\n",
    "r2_gradient_improved = r2_score(y_test_reg, y_pred_reg_best)\n",
    "\n",
    "print(\"Улучшенный градиентный бустинг:\")\n",
    "print(f\"MSE: {mse_gradient_improved:.4f}\")\n",
    "print(f\"MAE: {mae_gradient_improved:.4f}\")\n",
    "print(f\"R²: {r2_gradient_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем собственную версию градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGradientBoosting(BaseEstimator):\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, task='classification'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.task = task\n",
    "        self.trees = []\n",
    "        self.init_value = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение градиентного бустинга.\"\"\"\n",
    "        # Определяем начальное значение\n",
    "        if self.task == 'classification':\n",
    "            self.init_value = np.log(np.mean(y) / (1 - np.mean(y)))  # Для классификации\n",
    "        else:\n",
    "            self.init_value = np.mean(y)  # Для регрессии\n",
    "\n",
    "        # Инициализация предсказаний\n",
    "        y_pred = np.full(y.shape, self.init_value, dtype=np.float64)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Вычисление ошибок\n",
    "            if self.task == 'classification':\n",
    "                residuals = y - (1 / (1 + np.exp(-y_pred)))  # Используем логистическую функцию для классификации\n",
    "            else:\n",
    "                residuals = y - y_pred  # Для регрессии\n",
    "\n",
    "            # Выбор типа дерева\n",
    "            if self.task == 'classification':\n",
    "                tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            else:\n",
    "                tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "\n",
    "            # Обучение дерева на остатках\n",
    "            tree.fit(X, residuals)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            # Обновление предсказаний\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание значений.\"\"\"\n",
    "        y_pred = np.full(X.shape[0], self.init_value, dtype=np.float64)\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "\n",
    "        if self.task == 'classification':\n",
    "            return (y_pred > 0).astype(int)  # Бинарная классификация\n",
    "        return y_pred  # Для регрессии\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Предсказание вероятностей для классификации.\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return 1 / (1 + np.exp(-y_pred))  # Логистическая функция\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели и вывод полученных метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собственная реализация градиентного бустинга:\n",
      "MSE: 0.3630\n",
      "MAE: 0.4858\n",
      "R²: 0.4445\n"
     ]
    }
   ],
   "source": [
    "# Собственная реализация градиентного бустинга для регрессии\n",
    "custom_gb_regressor = CustomGradientBoosting(n_estimators=100, learning_rate=0.1, max_depth=3, task='regression')\n",
    "custom_gb_regressor.fit(X_train, y_train_reg)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_custom_reg = custom_gb_regressor.predict(X_test)\n",
    "\n",
    "# Оценка метрик\n",
    "mse_gradient_custom = mean_squared_error(y_test_reg, y_pred_custom_reg)\n",
    "mae_gradient_custom = mean_absolute_error(y_test_reg, y_pred_custom_reg)\n",
    "r2_gradient_custom = r2_score(y_test_reg, y_pred_custom_reg)\n",
    "\n",
    "print(\"Собственная реализация градиентного бустинга:\")\n",
    "print(f\"MSE: {mse_gradient_custom:.4f}\")\n",
    "print(f\"MAE: {mae_gradient_custom:.4f}\")\n",
    "print(f\"R²: {r2_gradient_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод и сравнение всех метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение результатов:\n",
      "Бейзлайн MSE: 0.3623, Улучшенная MSE: 0.3454, Custom MSE: 0.3630\n",
      "Бейзлайн MAE: 0.4849, Улучшенная MAE: 0.4554, Custom MAE: 0.4858\n",
      "Бейзлайн R²: 0.4456, Улучшенная R²: 0.4715, Custom R²: 0.4445\n"
     ]
    }
   ],
   "source": [
    "print(\"Сравнение результатов:\")\n",
    "print(f\"Бейзлайн MSE: {mse_gradient:.4f}, Улучшенная MSE: {mse_gradient_improved:.4f}, Custom MSE: {mse_gradient_custom:.4f}\")\n",
    "print(f\"Бейзлайн MAE: {mae_gradient:.4f}, Улучшенная MAE: {mae_gradient_improved:.4f}, Custom MAE: {mae_gradient_custom:.4f}\")\n",
    "print(f\"Бейзлайн R²: {r2_gradient:.4f}, Улучшенная R²: {r2_gradient_improved:.4f}, Custom R²: {r2_gradient_custom:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
